{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from glom import glom\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, Load, Extract, Save Physioloigcal Signal (Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class readloadsignal:\n",
    "    '''\n",
    "    This classreads and load physiological signals exported from fitbit. It extracts the heart rate (json file), estimated oxygen variation (csv file)\n",
    "    and skin temperature (csv file) and saves as seperate folders into specified directory\n",
    "    '''\n",
    "\n",
    "    def __init__(self,filenamejson,filenamecsv):\n",
    "        self.filenamejson = filenamejson\n",
    "        self.filenamecsv = filenamecsv\n",
    "\n",
    "    def extractvaluejson(self):\n",
    "\n",
    "        '''\n",
    "        This method reads and extracts the heartrate from the input jsonfile for heartrate from fitbit\n",
    "        '''\n",
    "\n",
    "        df = pd.read_json(self.filenamejson)\n",
    "        df_1 = df[\"value\"].apply(lambda row:glom(row,\"bpm\"))\n",
    "        df_2 = df[\"value\"].apply(lambda row:glom(row, \"confidence\"))\n",
    "        df_3 = df[\"dateTime\"]\n",
    "        df = pd.concat([df_3, df_2, df_1], axis=1, ignore_index=True)\n",
    "        df.columns = [\"datetime\",\"heartrate\",\"confidence\"] #rename column\n",
    "        df.set_index(\"datetime\",inplace=True)\n",
    "        df = df.loc[\"2022-06-15 18:45:00\": \"2022-06-15 20:00:00\"]\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def extractvaluecsv(self):\n",
    "\n",
    "        '''\n",
    "        This method reads and extracts the skintemp and estimated oxygen variation from the input csv files from fitbit\n",
    "        '''\n",
    "\n",
    "        column_dict = {\"timestamp\":\"datetime\", \"recorded_time\":\"datetime\", \"dateTime\":\"datetime\"}\n",
    "\n",
    "        df = pd.read_csv(self.filenamejson)\n",
    "        df.rename(columns=column_dict, inplace=True)\n",
    "        df.datetime = pd.to_datetime(df['datetime'],format=\"%Y-%m-%dT%H:%M:%S\", errors = 'coerce' )\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "        df = df.sort_index().loc[\"2022-06-15 18:41\":\"2022-06-15 20:00\"]\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def savesignal(self):\n",
    "\n",
    "        '''\n",
    "        This method saves each extracted physiological signal as a sepreate csv into specified directory\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            df = self.extractvaluejson()\n",
    "        except ValueError:\n",
    "            df = self.extractvaluecsv()\n",
    "        df.to_csv('Extracted data 2/{}.csv'.format(self.filenamecsv))\n",
    "        print(\"signal successfully saved\")\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal successfully saved\n"
     ]
    }
   ],
   "source": [
    "df_hr = readloadsignal(\"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/MyFitbitData version 2/OlumideOdetunde/Physical Activity/heart_rate-2022-06-15.json\",\"df_hr\")\n",
    "df_hr.extractvaluejson()\n",
    "df_hr.savesignal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skin Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal successfully saved\n"
     ]
    }
   ],
   "source": [
    "df_skt = readloadsignal(\"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/MyFitbitData version 2/OlumideOdetunde/Sleep/Wrist Temperature - 2022-06-15.csv\",\"df_skt\")\n",
    "df_skt.extractvaluecsv()\n",
    "df_skt.savesignal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Estimated O2 Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal successfully saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/7mfrmh2s0r17tk3yntzzmsjw0000gn/T/ipykernel_34485/4214935479.py:40: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  df = df.sort_index().loc[\"2022-06-15 18:41\":\"2022-06-15 20:00\"]\n",
      "/var/folders/1t/7mfrmh2s0r17tk3yntzzmsjw0000gn/T/ipykernel_34485/4214935479.py:40: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  df = df.sort_index().loc[\"2022-06-15 18:41\":\"2022-06-15 20:00\"]\n"
     ]
    }
   ],
   "source": [
    "df_eo = readloadsignal(\"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/MyFitbitData version 2/OlumideOdetunde/Other/estimated_oxygen_variation-2022-06-15.csv\", \"df_eo\")\n",
    "df_eo.extractvaluecsv()\n",
    "df_eo.savesignal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation (Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aligndatset:\n",
    "\n",
    "    '''\n",
    "    Argument: In positional order takes in extracted csvs of heart rate, estimated oxygen variation, skin temperature from the readloadsignal class.\n",
    "            Followed by excel file of data label and intended name of combined dataset created \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,filenamecsv1,filenamecsv2,filenamecsv3, filenameexcel,final_df):\n",
    "        self.filenamecsv1 = filenamecsv1\n",
    "        self.filenamecsv2 = filenamecsv2\n",
    "        self.filenamecsv3 = filenamecsv3\n",
    "        self.filenameexcel = filenameexcel\n",
    "        self.final_df = final_df \n",
    "\n",
    "    def read_clean_signals (self):\n",
    "\n",
    "        '''\n",
    "        This method  reads the first three csv entered and saves created dataframes into a list\n",
    "        '''\n",
    "\n",
    "        csv_files = [self.filenamecsv1, self.filenamecsv2, self.filenamecsv3]\n",
    "        dfs = []\n",
    "\n",
    "        for csv in csv_files:\n",
    "            column_droplist = [\"Unnamed: 0\"]\n",
    "            df  = pd.read_csv(csv)\n",
    "            df.drop(column_droplist,axis=1,inplace=True)\n",
    "            df[\"datetime\"] = pd.to_datetime(df.datetime)\n",
    "            dfs.append(df)\n",
    "        return dfs\n",
    "\n",
    "    def merge_signals(self):\n",
    "\n",
    "        '''\n",
    "        This method merges the the three dataframes obatined from the readcleansignal method call on date time using closest key align technique\n",
    "        '''\n",
    "\n",
    "        column_renamelist = {\"Infrared to Red Signal Ratio\":\"est_02_variation\", \"temperature\":\"skin_temp\",\"heartrate\":\"heart_rate\"}\n",
    "        column_droplist = [\"confidence\"]\n",
    "        df1, df2, df3 = self.read_clean_signals()\n",
    "\n",
    "        df_total = pd.merge_asof(df1, df2, on=\"datetime\",direction=\"backward\",\\\n",
    "            tolerance=pd.Timedelta(seconds = 60),allow_exact_matches=True)\n",
    "        df_total = pd.merge_asof(df_total,df3, on=\"datetime\",direction=\"nearest\",\\\n",
    "            tolerance=pd.Timedelta(seconds = 60),allow_exact_matches=True)\n",
    "        df_total.rename(columns=column_renamelist, inplace=True)\n",
    "        df_total.drop(column_droplist, inplace=True, axis=1)\n",
    "\n",
    "        return df_total\n",
    "\n",
    "    def load_datalabel(self):\n",
    "\n",
    "        '''\n",
    "        This method reads the data label excel file and divides into three dataframes using specified datetimes peculiar to this project\n",
    "        '''\n",
    "        \n",
    "        #Load and extract data label\n",
    "        df_dl = pd.read_excel(self.filenameexcel)\n",
    "        df_dl.drop([\"UserID\",\"Soundgroup\",\"Soundgroupselection\"], axis=1, inplace=True)\n",
    "        df_dl[[\"Starttime\", \"Endtime\"]] = df_dl[[\"Starttime\",\"Endtime\"]].apply(pd.to_datetime)\n",
    "        df_dl[\"datetime\"] = df_dl[\"Starttime\"] + timedelta(seconds = 6)\n",
    "        \n",
    "        #Create 3 dataframe with different time frames\n",
    "\n",
    "        #Dataframe with Starttime\n",
    "        df_dl_start = df_dl.drop([\"datetime\",\"Endtime\"], axis=1)\n",
    "        df_dl_start.rename(columns={\"Starttime\":\"datetime\"}, inplace=True)\n",
    "\n",
    "        #Dataframe with starttime plus six seconds\n",
    "        df_dl_after6sec = df_dl.drop([\"Starttime\",\"Endtime\"], axis=1)\n",
    "\n",
    "        #Dataframe with endtime\n",
    "        df_dl_end = df_dl.drop([\"datetime\",\"Starttime\"], axis=1)\n",
    "        df_dl_end.rename(columns={\"Endtime\":\"datetime\"},inplace=True)\n",
    "\n",
    "        return df_dl_start, df_dl_after6sec, df_dl_end\n",
    "\n",
    "    def initial_dataset_merge (self):\n",
    "\n",
    "        '''\n",
    "        This method performs an inital merge using the three dataframes (created by the load_datalabel method call) and combined physiological\n",
    "        signal dataframe (created by the merge_signal method call). Returns three unique dataframe of physiological signals merged to \n",
    "        the three data label dataframes\n",
    "        '''\n",
    "\n",
    "        df_dl_start, df_dl_after6sec, df_dl_end = self.load_datalabel()\n",
    "        df_total = self. merge_signals()\n",
    "\n",
    "        df_dataset_1 = pd.merge_asof(df_dl_start, df_total, on=\"datetime\",direction=\"nearest\", tolerance=pd.Timedelta(seconds=3),allow_exact_matches=True)\n",
    "\n",
    "        df_dataset_2 = pd.merge_asof(df_dl_after6sec, df_total, on=\"datetime\",direction=\"nearest\", tolerance=pd.Timedelta(seconds=3),allow_exact_matches=True)\n",
    "       \n",
    "        df_dataset_3 = pd.merge_asof(df_dl_end, df_total, on=\"datetime\",direction=\"nearest\", tolerance=pd.Timedelta(seconds=3),allow_exact_matches=True)\n",
    "\n",
    "        return df_dataset_1, df_dataset_2, df_dataset_3\n",
    "\n",
    "    def final_dataset_merge (self):\n",
    "\n",
    "        '''\n",
    "        This method uses the combines the  three dataframes returned by the initial_dataset_merge method call and groups by selected key columns\n",
    "        and generates required statistical features.\n",
    "\n",
    "        '''\n",
    "\n",
    "        df_dataset_1, df_dataset_2, df_dataset_3 = self.initial_dataset_merge()\n",
    "\n",
    "        df_dataset = pd.concat([df_dataset_1,df_dataset_2,df_dataset_3])\n",
    "        df_dataset.sort_values(by=[\"SoundID\"], inplace=True)\n",
    "\n",
    "        #Groupby soundid and datetime\n",
    "        df_dataset = df_dataset.groupby([\"SoundID\",\"datetime\",\"Emotion\"]).mean()\n",
    "        df_dataset.sort_values(\"datetime\",inplace=True)\n",
    "        df_dataset.reset_index(inplace=True)\n",
    "\n",
    "        #derive statistical features\n",
    "        df_dataset = df_dataset.groupby([\"SoundID\"]).agg({\"datetime\":max, \"Emotionrating\":\"mean\",\"Emotion\":max, \"heart_rate\":['mean', 'std'],\"skin_temp\":['mean', \"std\"],}) #\"est_02_variation\":\"mean\"}) #est 02 variation was empty here mightnot be in other cases\n",
    "        return df_dataset\n",
    "\n",
    "    def save_final_dataset (self):\n",
    "\n",
    "        '''\n",
    "        This method saves the combined and final dataset created by the final_data_set_merge method call into a specified directory\n",
    "        '''\n",
    "        \n",
    "        df = self.final_dataset_merge()\n",
    "        df.to_csv('Extracted data 2/{}.csv'.format(self.final_df))\n",
    "        print (\"combined dataset successfully created\")\n",
    "        print(df.head())\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User 001 - First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined dataset successfully created\n",
      "                   datetime Emotionrating    Emotion heart_rate       \\\n",
      "                        max          mean        max       mean  std   \n",
      "SoundID                                                                \n",
      "0085_2  2022-06-15 19:49:53           1.0    Sadness        1.0  0.0   \n",
      "0109_2  2022-06-15 18:54:15           7.0  Happiness        2.0  0.0   \n",
      "0123_2  2022-06-15 19:16:38           3.0       Fear        NaN  NaN   \n",
      "0124_2  2022-06-15 18:52:32           4.0  Happiness        3.0  0.0   \n",
      "0149_2  2022-06-15 19:27:09           4.0       Fear        1.0  0.0   \n",
      "\n",
      "        skin_temp       \n",
      "             mean  std  \n",
      "SoundID                 \n",
      "0085_2   1.534936  0.0  \n",
      "0109_2   0.499936  0.0  \n",
      "0123_2        NaN  NaN  \n",
      "0124_2   0.259936  0.0  \n",
      "0149_2   1.619936  0.0  \n"
     ]
    }
   ],
   "source": [
    "df_combined= aligndatset(\"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/Extracted data 2/df_hr.csv\",\n",
    "                            \"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/Extracted data 2/df_eo.csv\",\n",
    "                            \"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/Extracted data 2/df_skt.csv\",\n",
    "                            \"/Users/olumide/Documents/Dissertation/Sound Stimuli version 1/Excel Database.xlsx\",\n",
    "                            \"df_combinedined_user001_exp001\" )\n",
    "df_combined.read_clean_signals()\n",
    "df_combined.merge_signals()\n",
    "df_combined.load_datalabel()\n",
    "df_combined.initial_dataset_merge()\n",
    "df_combined.final_dataset_merge()\n",
    "df_combined.save_final_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1708efda55cb6d4aeb89181de40d53c5ba9d56028be66cf6cf1da196ab6b8121"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
